{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db3eb955",
   "metadata": {},
   "source": [
    "# BERT\n",
    "Bidirectional encoder representations from transformers(BERT) is a word embedding technique that uses the transformer architecture.\\\n",
    "It is a truely bidirectional model and takes in context from both the left and right of the word to embed to get the correct meaning of the word and solve the ambiguity.\\\n",
    "It uses 2 pretraining stratergies to make it bidirectional\n",
    "1. Masked Language Model (MLM) - Where it hides 15% of the words randomly\n",
    "2. Next Sentence Prediction (NSP) - Where it predicts the probabilty of a sentence following another one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ab6ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "text = \"ChatGPT is a language model developed by OpenAI, based on the GPT (Generative Pre-trained Transformer) architecture.\"\n",
    "\n",
    "# Tokenize and encode the text\n",
    "encoding = tokenizer(text, return_tensors=\"pt\")\n",
    "input_ids = encoding[\"input_ids\"]\n",
    "attention_mask = encoding[\"attention_mask\"]\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "print(\"Tokens:\", tokens)\n",
    "\n",
    "# Get embeddings from BERT\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids, attention_mask=attention_mask)\n",
    "embeddings = outputs.last_hidden_state  # shape: (1, seq_len, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f0537db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding vector for 'ChatGPT': [ 0.18248466  0.06531088 -0.01304259 -0.10080975 -0.41819397  0.12474632\n",
      "  0.01837833  0.40949067 -0.05134635 -0.5909524  -0.2686349   0.46541452\n",
      " -0.6358447   0.11812568 -0.587759   -0.13893628  0.07554506 -0.13657925\n",
      " -0.33382833 -0.05356705 -0.03662148 -0.31187272  0.18614851 -0.3344482\n",
      " -0.23796754 -0.2935622   0.13455424  0.20183997 -0.48891345  0.03939801\n",
      "  0.24702975 -0.09962103  0.1313757  -0.05996384 -0.00407322  0.08232902\n",
      " -0.0035517   0.06007571  0.17209187  0.48715696  0.43790358  0.38488567\n",
      "  0.3372156  -0.11275385  0.11603636 -0.08879892 -0.02702014  0.4166429\n",
      " -0.23614068  0.19281545]\n",
      "Shape: torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "word_tokens = [\"Cha\", \"##t\", \"##GP\", \"##T\"]\n",
    "word_indices = [i for i, t in enumerate(tokens) if t in word_tokens]\n",
    "\n",
    "chatgpt_embedding = embeddings[0, word_indices, :].mean(dim=0)\n",
    "print(\"Embedding vector for 'ChatGPT':\", chatgpt_embedding.numpy()[:50])\n",
    "print(\"Shape:\", chatgpt_embedding.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
